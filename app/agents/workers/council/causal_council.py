"""
Stage D: Multi-Agent Causal Council — cross-trend causal reasoning.

Architecture: Three-stage funnel that discovers cause-effect relationships
between trends with minimal LLM cost.

  Agent 1: CausalPreFilter (0 LLM calls)
    Takes correlation edges from Layer 3 + per-cluster causal_chains.
    Scores pairs by entity bridge strength, temporal lag, sector chain.
    Pre-filters O(n²) possible pairs down to ~5-10 candidates.

  Agent 2: CausalMechanismAgent (1 LLM call per candidate pair)
    For each pre-filtered pair: reads both clusters' causal_chains,
    key_entities, trend_summaries, shared bridge entities.
    LLM determines: Is this causal? What's the mechanism? Direction?

  Agent 3: CascadeNarrativeAgent (1 LLM call per cascade chain)
    Takes cascade paths (chains of 3+ clusters) from correlation.py.
    LLM generates coherent chain-reaction narrative with evidence.

  Agent 4: EvidenceValidator (0 LLM calls)
    Validates all causal edges against source articles using NER +
    keyword matching. Filters hallucinated connections.

LLM Budget: ~5-10 pre-filtered pairs + ~2-3 cascades = ~7-13 calls total.

Research backing:
- Three-Stage Causal Funnel pattern (0-cost pre-filter → plausibility → LLM)
- Per-cluster causal_chain already generated by synthesis — we concatenate
  and cross-reference rather than re-derive
- Entity bridges (IDF-weighted) from correlation.py provide statistical
  grounding before any LLM reasoning
"""

import asyncio
import logging
import time
from collections import Counter
from typing import Any, Dict, List, Optional, Tuple

from .schemas import CausalEdgeResult, CascadeNarrative, CausalCouncilResult
from ....schemas.llm_outputs import CausalEdgeLLM, CascadeNarrativeLLM
from ....tools.llm_service import LLMService

logger = logging.getLogger(__name__)


# ══════════════════════════════════════════════════════════════════════════
# AGENT 1: CAUSAL PRE-FILTER (0 LLM calls)
# ══════════════════════════════════════════════════════════════════════════

def _prefilter_causal_candidates(
    tree_nodes: Dict[str, Any],
    trend_edges: List[Dict],
    cascades: List[List[int]],
    cluster_id_to_node_id: Dict[int, str],
    max_candidates: int = 10,
) -> List[Dict[str, Any]]:
    """Pre-filter trend pairs that are likely causal using statistical signals.

    Scoring formula (no LLM, instant):
      score = (0.35 * bridge_strength) + (0.35 * temporal_signal) + (0.3 * sector_chain_bonus)

    Where:
      bridge_strength: IDF-weighted entity overlap from correlation.py (0-1)
      temporal_signal: 1.0 if lag > 2h (one precedes the other), 0.3 if co-occurring
      sector_chain_bonus: 1.0 if sector chain match exists, 0.0 otherwise

    Returns candidate pairs sorted by score, capped at max_candidates.
    """
    if not trend_edges:
        logger.info("CausalPreFilter: No correlation edges to evaluate")
        return []

    candidates = []
    for edge in trend_edges:
        src_cid = edge.get("source")
        tgt_cid = edge.get("target")
        src_nid = cluster_id_to_node_id.get(src_cid, "")
        tgt_nid = cluster_id_to_node_id.get(tgt_cid, "")

        if not src_nid or not tgt_nid:
            continue

        src_node = tree_nodes.get(src_nid)
        tgt_node = tree_nodes.get(tgt_nid)
        if not src_node or not tgt_node:
            continue

        # Component scores
        bridge_strength = min(edge.get("strength", 0.0), 1.0)

        # Smooth temporal signal: scales from 0.3 (no lag) to 1.0 (3h+ lag)
        lag_hours = abs(edge.get("lag_hours", 0.0))
        temporal_signal = min(1.0, 0.3 + 0.7 * min(1.0, lag_hours / 3.0))

        sector_chain = edge.get("sector_chain")
        sector_bonus = 1.0 if sector_chain else 0.0

        # Entity bridge bonus: edges with actual shared entities have higher
        # causal potential than pure semantic similarity (topic overlap).
        # Without this, semantic centroid edges (high cosine sim but no
        # shared entities) dominate the top-10 and crowd out entity bridges.
        shared_ents = edge.get("bridge_entities", [])
        entity_bridge_bonus = min(1.0, len(shared_ents) * 0.25) if shared_ents else 0.0

        # Composite pre-filter score
        score = (
            0.25 * bridge_strength
            + 0.25 * temporal_signal
            + 0.25 * sector_bonus
            + 0.25 * entity_bridge_bonus
        )

        # Bonus: both clusters have causal_chains (LLM already reasoned about them)
        src_has_chain = bool(getattr(src_node, 'causal_chain', None))
        tgt_has_chain = bool(getattr(tgt_node, 'causal_chain', None))
        if src_has_chain and tgt_has_chain:
            score += 0.1  # Small bonus for richer context

        candidates.append({
            "source_node_id": src_nid,
            "target_node_id": tgt_nid,
            "source_cluster_id": src_cid,
            "target_cluster_id": tgt_cid,
            "prefilter_score": round(score, 3),
            "bridge_strength": bridge_strength,
            "temporal_lag_hours": edge.get("lag_hours", 0.0),
            "sector_chain": sector_chain,
            "shared_entities": edge.get("bridge_entities", [])[:10],
            "relationship_hint": edge.get("relationship", "co-occurs"),
        })

    # Sort by score descending, take top candidates
    candidates.sort(key=lambda c: c["prefilter_score"], reverse=True)
    top = candidates[:max_candidates]

    logger.info(
        f"CausalPreFilter: {len(trend_edges)} edges → {len(top)} candidates "
        f"(threshold: top-{max_candidates} by score)"
    )
    for c in top:
        src = tree_nodes.get(c["source_node_id"])
        tgt = tree_nodes.get(c["target_node_id"])
        logger.info(
            f"  [{c['prefilter_score']:.2f}] "
            f"'{getattr(src, 'trend_title', '?')[:40]}' → "
            f"'{getattr(tgt, 'trend_title', '?')[:40]}' "
            f"(entities: {c['shared_entities'][:3]}, hint: {c['relationship_hint']})"
        )

    return top


# ══════════════════════════════════════════════════════════════════════════
# AGENT 2: CAUSAL MECHANISM AGENT (1 LLM call per candidate)
# ══════════════════════════════════════════════════════════════════════════

CAUSAL_MECHANISM_SYSTEM = """You are a causal reasoning analyst specializing in Indian business markets.

Your task: Determine whether two news trends have a meaningful causal or amplification
relationship, or are merely coincidental co-occurrences.

These trend pairs have ALREADY been pre-filtered as statistically likely to be connected.
Your job is to determine the NATURE of the connection — not whether one exists.

RULES:
1. A causal/amplification link requires a PLAUSIBLE TRANSMISSION MECHANISM
2. Use your knowledge of Indian business economics to identify mechanisms
   (e.g., "RBI rate hike → higher NBFC borrowing costs → reduced lending" is valid)
3. Temporal ordering supports but is not required for amplification (concurrent events can amplify each other)
4. "amplifies" is common and valuable — events from the same context often strengthen each other
   (e.g., government AI summit → AI investment announcements are "amplifies")
5. "co-occurs" is for trends that are genuinely unrelated despite surface similarity

Relationship types:
- "causes": Trend A directly leads to Trend B through a specific mechanism
- "amplifies": Trend A strengthens or contextualizes Trend B (most common causal type for news events)
- "mitigates": Trend A reduces or counteracts the effect of Trend B
- "co-occurs": Trends are genuinely unrelated — no plausible transmission mechanism exists
"""

CAUSAL_MECHANISM_PROMPT = """Analyze whether these two trends have a causal relationship:

## TREND A: {source_title}
Summary: {source_summary}
Causal Chain: {source_chain}
Key Entities: {source_entities}
Event Type: {source_event}

## TREND B: {target_title}
Summary: {target_summary}
Causal Chain: {target_chain}
Key Entities: {target_entities}
Event Type: {target_event}

## STATISTICAL EVIDENCE (pre-computed)
Shared Entities: {shared_entities}
Temporal Lag: {temporal_lag} (positive = A precedes B)
Sector Chain: {sector_chain}
Pre-filter Score: {prefilter_score}

## YOUR TASK
1. In your reasoning, identify the PLAUSIBLE mechanism by which A could cause/amplify/mitigate B
2. Consider: Is there a transmission channel? (policy → cost → margin, event → announcement → reaction)
3. Consider: Do the trends arise from the same catalyst or context? (If so, "amplifies" is likely)
4. Consider: Does temporal ordering support the causal direction?
5. Set is_causal=true if you can identify a plausible mechanism — it doesn't need to be proven, just reasonable
6. Set is_causal=false ONLY if the trends are genuinely unrelated despite surface similarity
"""


async def _evaluate_causal_pair(
    llm_service: LLMService,
    candidate: Dict[str, Any],
    tree_nodes: Dict[str, Any],
    semaphore: asyncio.Semaphore,
) -> Optional[CausalEdgeResult]:
    """Evaluate a single candidate pair via LLM (Agent 2).

    Returns CausalEdgeResult if the LLM confirms causality, None otherwise.
    """
    src_node = tree_nodes.get(candidate["source_node_id"])
    tgt_node = tree_nodes.get(candidate["target_node_id"])
    if not src_node or not tgt_node:
        return None

    # Provide meaningful context for shared entities or semantic connection
    shared_ents = candidate.get("shared_entities", [])
    if shared_ents:
        shared_entities_text = ", ".join(shared_ents)
    else:
        shared_entities_text = (
            "None (trends linked via semantic similarity in article content — "
            "they discuss related topics without sharing named entities)"
        )

    prompt = CAUSAL_MECHANISM_PROMPT.format(
        source_title=getattr(src_node, 'trend_title', ''),
        source_summary=getattr(src_node, 'trend_summary', '')[:500],
        source_chain="\n".join(getattr(src_node, 'causal_chain', [])[:4]),
        source_entities=", ".join(getattr(src_node, 'key_entities', [])[:8]),
        source_event=getattr(src_node, 'validated_event_type', '') or getattr(src_node, 'signals', {}).get('dominant_event', ''),
        target_title=getattr(tgt_node, 'trend_title', ''),
        target_summary=getattr(tgt_node, 'trend_summary', '')[:500],
        target_chain="\n".join(getattr(tgt_node, 'causal_chain', [])[:4]),
        target_entities=", ".join(getattr(tgt_node, 'key_entities', [])[:8]),
        target_event=getattr(tgt_node, 'validated_event_type', '') or getattr(tgt_node, 'signals', {}).get('dominant_event', ''),
        shared_entities=shared_entities_text,
        temporal_lag=f"{candidate.get('temporal_lag_hours', 0):.1f} hours",
        sector_chain=candidate.get("sector_chain", "None detected"),
        prefilter_score=candidate.get("prefilter_score", 0),
    )

    async with semaphore:
        try:
            result: CausalEdgeLLM = await llm_service.run_structured(
                prompt=prompt,
                system_prompt=CAUSAL_MECHANISM_SYSTEM,
                output_type=CausalEdgeLLM,
            )
        except Exception:
            # Track A (structured output) failed — fall back to Track B (raw JSON)
            try:
                raw = await llm_service.generate_json(
                    prompt=prompt,
                    system_prompt=CAUSAL_MECHANISM_SYSTEM,
                    pydantic_model=CausalEdgeLLM,
                )
                result = CausalEdgeLLM(**raw)
            except Exception as e2:
                logger.warning(f"CausalMechanism LLM failed (both tracks): {e2}")
                return None

    if not result.is_causal:
        logger.info(
            f"CausalMechanism: REJECTED "
            f"'{getattr(src_node, 'trend_title', '')[:40]}' → "
            f"'{getattr(tgt_node, 'trend_title', '')[:40]}' "
            f"(type={result.relationship_type}, reason: {result.reasoning[:120]})"
        )
        return None

    # Determine direction
    src_id = candidate["source_node_id"]
    tgt_id = candidate["target_node_id"]
    if result.direction == "b_to_a":
        src_id, tgt_id = tgt_id, src_id

    edge = CausalEdgeResult(
        source_node_id=src_id,
        target_node_id=tgt_id,
        source_title=getattr(tree_nodes.get(src_id), 'trend_title', ''),
        target_title=getattr(tree_nodes.get(tgt_id), 'trend_title', ''),
        relationship_type=result.relationship_type,
        causal_mechanism=result.causal_mechanism,
        strength=candidate.get("prefilter_score", 0.0),
        confidence=result.confidence,
        evidence_quotes=result.evidence_quotes[:5],
        business_implication=result.business_implication,
        detection_method="llm_causal",
        shared_entities=candidate.get("shared_entities", []),
    )

    logger.info(
        f"CausalMechanism: CONFIRMED [{result.relationship_type}] "
        f"'{edge.source_title[:30]}' → '{edge.target_title[:30]}' "
        f"(confidence: {result.confidence:.2f}, mechanism: {result.causal_mechanism[:80]})"
    )
    return edge


# ══════════════════════════════════════════════════════════════════════════
# AGENT 3: CASCADE NARRATIVE AGENT (1 LLM call per cascade)
# ══════════════════════════════════════════════════════════════════════════

CASCADE_NARRATIVE_SYSTEM = """You are a chain-reaction analyst for Indian business markets.

Your task: Given a sequence of 3+ linked trends that form a cascade (chain reaction),
write a coherent narrative explaining HOW each trend triggers the next.

CRITICAL RULES:
1. Each hop must have a SPECIFIC mechanism (not "this leads to that" — say HOW)
2. Use concrete data from the trend summaries (numbers, names, dates)
3. The narrative must read as a compelling business brief, not an academic paper
4. Identify the WEAKEST link — where is the evidence thinnest?
5. End with a compound business implication: what must companies do knowing the FULL chain?
"""

CASCADE_NARRATIVE_PROMPT = """Analyze this chain of {n_trends} linked trends and write a cascade narrative:

{trends_context}

## STATISTICAL EVIDENCE
These trends were linked by: entity bridges (shared entities between consecutive trends),
temporal ordering (earlier trends precede later ones), and sector chain matching.

## YOUR TASK
1. For each hop (A→B, B→C, etc.), explain the SPECIFIC transmission mechanism
2. Write a single-paragraph cascade_narrative telling the full chain-reaction story
3. Identify the weakest link in the chain
4. Describe the COMPOUND business impact (what's the effect of the FULL chain, not just individual trends?)
"""


async def _build_cascade_narratives(
    llm_service: LLMService,
    cascades: List[List[int]],
    tree_nodes: Dict[str, Any],
    cluster_id_to_node_id: Dict[int, str],
    semaphore: asyncio.Semaphore,
    max_cascades: int = 3,
) -> List[CascadeNarrative]:
    """Build chain-reaction narratives for cascade paths (Agent 3).

    Each cascade is a list of cluster IDs forming a chain: [A, B, C, ...]
    meaning A → B → C in causal sequence.
    """
    if not cascades:
        return []

    # Take longest/most interesting cascades first
    sorted_cascades = sorted(cascades, key=len, reverse=True)[:max_cascades]
    results = []

    for i, cascade_cids in enumerate(sorted_cascades):
        # Map cluster IDs to node IDs
        node_ids = []
        node_titles = []
        for cid in cascade_cids:
            nid = cluster_id_to_node_id.get(cid, "")
            node = tree_nodes.get(nid) if nid else None
            if node:
                node_ids.append(nid)
                node_titles.append(getattr(node, 'trend_title', f'Cluster {cid}'))

        if len(node_ids) < 3:
            continue

        # Build context for each trend in the chain
        trends_context_parts = []
        for idx, nid in enumerate(node_ids):
            node = tree_nodes[nid]
            chain_str = "\n".join(getattr(node, 'causal_chain', [])[:4])
            trends_context_parts.append(
                f"### Trend {idx + 1}: {getattr(node, 'trend_title', '')}\n"
                f"Summary: {getattr(node, 'trend_summary', '')[:400]}\n"
                f"Causal Chain:\n{chain_str}\n"
                f"Key Entities: {', '.join(getattr(node, 'key_entities', [])[:6])}\n"
            )

        prompt = CASCADE_NARRATIVE_PROMPT.format(
            n_trends=len(node_ids),
            trends_context="\n".join(trends_context_parts),
        )

        async with semaphore:
            try:
                result: CascadeNarrativeLLM = await llm_service.run_structured(
                    prompt=prompt,
                    system_prompt=CASCADE_NARRATIVE_SYSTEM,
                    output_type=CascadeNarrativeLLM,
                )
            except Exception:
                # Track A failed — fall back to Track B (raw JSON)
                try:
                    raw = await llm_service.generate_json(
                        prompt=prompt,
                        system_prompt=CASCADE_NARRATIVE_SYSTEM,
                        pydantic_model=CascadeNarrativeLLM,
                    )
                    result = CascadeNarrativeLLM(**raw)
                except Exception as e2:
                    logger.warning(f"CascadeNarrative LLM failed (both tracks) for cascade {i}: {e2}")
                    continue

        narrative = CascadeNarrative(
            cascade_id=f"cascade_{i}",
            node_ids=node_ids,
            node_titles=node_titles,
            narrative=result.cascade_narrative,
            hop_mechanisms=result.hop_mechanisms,
            confidence=result.cascade_confidence,
            weakest_link=result.weakest_link,
            compound_business_impact=result.compound_business_impact,
            total_hops=len(node_ids) - 1,
        )
        results.append(narrative)

        logger.info(
            f"CascadeNarrative: {' → '.join(t[:25] for t in node_titles)} "
            f"(confidence: {result.cascade_confidence:.2f}, hops: {narrative.total_hops})"
        )

    return results


# ══════════════════════════════════════════════════════════════════════════
# AGENT 4: EVIDENCE VALIDATOR (0 LLM calls)
# ══════════════════════════════════════════════════════════════════════════

def _validate_causal_evidence(
    edges: List[CausalEdgeResult],
    tree_nodes: Dict[str, Any],
    all_articles: List[Any],
) -> List[CausalEdgeResult]:
    """Validate causal edges against source article evidence (Agent 4).

    Uses NER entities + keyword matching to check if the LLM's causal
    claims are actually grounded in article content. Zero LLM calls.

    Validation checks:
    1. Shared entities must appear in BOTH clusters' articles (not hallucinated)
    2. Evidence quotes must be traceable to actual article content
    3. Causal mechanism keywords must appear in articles
    """
    if not edges:
        return []

    # Build article text index per node
    node_article_text: Dict[str, str] = {}
    for nid, node in tree_nodes.items():
        article_ids = set(str(aid) for aid in getattr(node, 'source_articles', []))
        texts = []
        for article in all_articles:
            if str(getattr(article, 'id', '')) in article_ids:
                texts.append(
                    (getattr(article, 'title', '') or '') + " " +
                    (getattr(article, 'content', '') or getattr(article, 'summary', '') or '')
                )
        node_article_text[nid] = " ".join(texts).lower()

    validated = []
    for edge in edges:
        src_text = node_article_text.get(edge.source_node_id, "")
        tgt_text = node_article_text.get(edge.target_node_id, "")
        combined = src_text + " " + tgt_text

        # Check 1: shared entities actually appear in articles
        # Use token-level matching: "Tata Consultancy Services" matches if
        # "tata" OR "consultancy" OR "services" appears (for multi-word entities).
        # Short entities (<=3 chars): require word-boundary match.
        import re
        combined_lower = combined.lower()
        entity_hits = 0
        for e in edge.shared_entities:
            e_lower = e.lower().strip()
            if len(e_lower) <= 3:
                pattern = r'(?<!\w)' + re.escape(e_lower) + r'(?!\w)'
                if re.search(pattern, combined_lower):
                    entity_hits += 1
            elif e_lower in combined_lower:
                entity_hits += 1
            else:
                # Token-level fallback: any significant token (>3 chars) matches
                tokens = [t for t in e_lower.split() if len(t) > 3]
                if tokens and any(t in combined_lower for t in tokens):
                    entity_hits += 1
        entity_ratio = entity_hits / max(len(edge.shared_entities), 1)

        # Check 2: mechanism keywords appear in articles
        # Use only the 12 longest words (most distinctive/domain-specific).
        # LLMs paraphrase, so expect partial match at best.
        mechanism_words_all = sorted(
            set(
                w.lower().strip(".,;:!?'\"")
                for w in edge.causal_mechanism.split()
                if len(w) > 4  # skip short common words
            ),
            key=len, reverse=True,
        )[:12]
        mechanism_hits = sum(1 for w in mechanism_words_all if w in combined)
        mechanism_ratio = mechanism_hits / max(len(mechanism_words_all), 1)

        # Check 3: evidence quotes are traceable
        # LLM "quotes" are usually paraphrases, so use lenient matching:
        # any 2 of the top-5 distinctive words appearing = traceable.
        quote_hits = 0
        for quote in edge.evidence_quotes:
            quote_words = sorted(
                [w.lower().strip(".,;:!?'\"") for w in quote.split() if len(w) > 4],
                key=len, reverse=True,
            )[:5]
            if quote_words:
                found = sum(1 for w in quote_words if w in combined)
                if found >= min(2, len(quote_words)):  # at least 2 words (or all if < 2)
                    quote_hits += 1
        quote_ratio = quote_hits / max(len(edge.evidence_quotes), 1)

        # Composite evidence score — weighting depends on whether we have
        # shared entities to validate against.
        if edge.shared_entities:
            # Entity bridges: entity_ratio is most reliable signal
            # (entities were extracted FROM articles). Mechanism and quotes
            # are LLM paraphrases, so weight them lower.
            evidence_score = (0.55 * entity_ratio) + (0.25 * mechanism_ratio) + (0.20 * quote_ratio)
        else:
            # Semantic/topically_related edges: no shared entities to check.
            # Connection was established via embedding similarity, so rely
            # on mechanism + quote grounding instead.
            evidence_score = (0.50 * mechanism_ratio) + (0.50 * quote_ratio)

        if evidence_score < 0.08:
            logger.info(
                f"EvidenceValidator: REJECTED '{edge.source_title[:30]}' → "
                f"'{edge.target_title[:30]}' "
                f"(evidence_score: {evidence_score:.2f}, "
                f"entities: {entity_ratio:.2f}, mechanism: {mechanism_ratio:.2f}, "
                f"quotes: {quote_ratio:.2f})"
            )
            continue

        # Adjust confidence based on evidence grounding (gentler penalty)
        if evidence_score >= 0.4:
            pass  # Good evidence — trust LLM confidence fully
        elif evidence_score >= 0.2:
            edge.confidence = round(edge.confidence * 0.9, 3)
        else:
            edge.confidence = round(edge.confidence * 0.7, 3)
        validated.append(edge)

        logger.debug(
            f"EvidenceValidator: PASSED '{edge.source_title[:30]}' → "
            f"'{edge.target_title[:30]}' (evidence: {evidence_score:.2f})"
        )

    logger.info(
        f"EvidenceValidator: {len(validated)}/{len(edges)} edges validated"
    )
    return validated


# ══════════════════════════════════════════════════════════════════════════
# ORCHESTRATOR: run_causal_council()
# ══════════════════════════════════════════════════════════════════════════

async def run_causal_council(
    tree: Any,
    trend_edges: List[Dict],
    cascades: List[List[int]],
    cluster_id_to_node_id: Dict[int, str],
    all_articles: List[Any],
    llm_service: Optional[LLMService] = None,
    max_candidates: int = 5,
    max_cascades: int = 2,
    concurrency: int = 5,
) -> CausalCouncilResult:
    """Orchestrate the 4-agent Causal Council pipeline.

    Args:
        tree: TrendTree with synthesized nodes
        trend_edges: Correlation edges from Layer 3 (List[Dict])
        cascades: Cascade paths from Layer 3 (List[List[int]])
        cluster_id_to_node_id: Maps cluster_id (int) → node UUID (str)
        all_articles: All articles for evidence validation
        llm_service: Shared LLMService instance
        max_candidates: Max pairs for LLM evaluation
        max_cascades: Max cascade chains for narrative generation
        concurrency: Max parallel LLM calls

    Returns:
        CausalCouncilResult with validated edges, narratives, and metrics
    """
    start = time.time()

    if llm_service is None:
        llm_service = LLMService()

    tree_nodes = tree.nodes
    semaphore = asyncio.Semaphore(concurrency)
    llm_calls = 0

    logger.info(
        f"CausalCouncil: Starting with {len(trend_edges)} edges, "
        f"{len(cascades)} cascades, {len(tree_nodes)} nodes"
    )

    # ── Agent 1: Pre-filter (0 LLM calls) ──
    candidates = _prefilter_causal_candidates(
        tree_nodes=tree_nodes,
        trend_edges=trend_edges,
        cascades=cascades,
        cluster_id_to_node_id=cluster_id_to_node_id,
        max_candidates=max_candidates,
    )

    # ── Agent 2: Causal mechanism evaluation (parallel LLM) ──
    edge_tasks = [
        _evaluate_causal_pair(llm_service, c, tree_nodes, semaphore)
        for c in candidates
    ]
    # ── Agent 3: Cascade narratives (parallel LLM) ──
    cascade_task = _build_cascade_narratives(
        llm_service, cascades, tree_nodes,
        cluster_id_to_node_id, semaphore, max_cascades,
    )

    # Run Agents 2 and 3 in parallel (timeout from config)
    try:
        from app.config import get_settings as _gs
        _inner_timeout = _gs().cross_trend_inner_timeout
    except Exception:
        _inner_timeout = 45.0
    try:
        edge_results_raw, cascade_narratives = await asyncio.wait_for(
            asyncio.gather(
                asyncio.gather(*edge_tasks),
                cascade_task,
            ),
            timeout=_inner_timeout,
        )
    except asyncio.TimeoutError:
        logger.error("CausalCouncil: Timed out after 300s — returning partial results")
        edge_results_raw = []
        cascade_narratives = []

    # Filter None results (rejected pairs)
    causal_edges = [e for e in edge_results_raw if e is not None]
    llm_calls = len(candidates) + len(cascade_narratives)

    # ── Agent 4: Evidence validation (0 LLM calls) ──
    validated_edges = _validate_causal_evidence(
        causal_edges, tree_nodes, all_articles,
    )

    elapsed = time.time() - start

    result = CausalCouncilResult(
        causal_edges=validated_edges,
        cascade_narratives=cascade_narratives,
        pairs_evaluated=len(candidates),
        pairs_pre_filtered=len(candidates),
        edges_confirmed=len(validated_edges),
        cascades_found=len(cascade_narratives),
        llm_calls_made=llm_calls,
        total_seconds=round(elapsed, 2),
    )

    logger.info(
        f"CausalCouncil: Complete in {elapsed:.1f}s — "
        f"{result.edges_confirmed} causal edges, "
        f"{result.cascades_found} cascade narratives "
        f"({llm_calls} LLM calls)"
    )

    return result


# ══════════════════════════════════════════════════════════════════════════
# HELPER: Apply causal results to TrendTree
# ══════════════════════════════════════════════════════════════════════════

def apply_causal_results(tree: Any, council_result: CausalCouncilResult) -> None:
    """Annotate TrendTree with causal council results (in-place mutation).

    Adds:
    - tree.causal_edges: List of validated causal edge dicts
    - tree.cascade_narratives: List of cascade narrative dicts
    - tree.causal_council_metrics: Summary metrics
    - Per-node signals["causal_links"]: list of edges involving this node
    """
    # Store on tree
    tree.causal_edges = [e.model_dump() for e in council_result.causal_edges]
    tree.cascade_narratives = [n.model_dump() for n in council_result.cascade_narratives]
    tree.causal_council_metrics = {
        "pairs_pre_filtered": council_result.pairs_pre_filtered,
        "pairs_evaluated": council_result.pairs_evaluated,
        "edges_confirmed": council_result.edges_confirmed,
        "cascades_found": council_result.cascades_found,
        "llm_calls_made": council_result.llm_calls_made,
        "total_seconds": council_result.total_seconds,
    }

    # Deduplicate edges before annotating (same pair can appear from cascades + direct)
    seen_edge_keys = set()
    unique_edges = []
    for edge in council_result.causal_edges:
        key = (edge.source_node_id, edge.target_node_id, edge.relationship_type)
        if key not in seen_edge_keys:
            seen_edge_keys.add(key)
            unique_edges.append(edge)

    # Annotate individual nodes with their causal links
    for edge in unique_edges:
        for nid in [edge.source_node_id, edge.target_node_id]:
            node = tree.nodes.get(nid)
            if node:
                links = node.signals.setdefault("causal_links", [])
                links.append({
                    "peer_node_id": edge.target_node_id if nid == edge.source_node_id else edge.source_node_id,
                    "peer_title": edge.target_title if nid == edge.source_node_id else edge.source_title,
                    "relationship": edge.relationship_type,
                    "mechanism": edge.causal_mechanism,
                    "role": "cause" if nid == edge.source_node_id else "effect",
                    "confidence": edge.confidence,
                })

    # Annotate nodes in cascades
    for narrative in council_result.cascade_narratives:
        for idx, nid in enumerate(narrative.node_ids):
            node = tree.nodes.get(nid)
            if node:
                cascade_info = node.signals.setdefault("cascade_membership", [])
                cascade_info.append({
                    "cascade_id": narrative.cascade_id,
                    "position": idx,
                    "total_hops": narrative.total_hops,
                    "narrative": narrative.narrative[:200],
                    "compound_impact": narrative.compound_business_impact[:200],
                })
